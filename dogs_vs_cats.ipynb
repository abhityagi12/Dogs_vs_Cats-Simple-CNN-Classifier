{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt \nimport matplotlib.image as img\nimport numpy as np\nimport pandas as pd\nimport os\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score\nfrom torch.autograd import Variable\nimport torch.utils.data as data\nimport torchvision\nfrom torchvision import transforms\nfrom torchvision.datasets import ImageFolder\nimport torch.optim as optim","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import zipfile\n\nDataset = \"dogs-vs-cats\"\n\n# Will unzip the files so that you can see them..\nwith zipfile.ZipFile(\"/kaggle/input/\"+Dataset+\"/test1.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with zipfile.ZipFile(\"/kaggle/input/\"+Dataset+\"/train.zip\",\"r\") as z:\n    z.extractall(\".\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('train_new')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('valid_new')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./valid_new/dogs')\nos.mkdir('./valid_new/cats')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('./train/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir('./train_new/cats')\nos.mkdir('./train_new/dogs')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import re","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import shutil","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=os.listdir('./train')\n# categories=[]\nfor i in data:\n    category=i.split('.')[0]\n#     print(category)\n    if category=='dog':\n        shutil.copy('./train/'+i,'./train_new/dogs/')\n    else:\n        shutil.move('./train/'+i,'./train_new/cats/')\n# df=pd.DataFrame({\n#     'filename':train,\n#     'caregory':categories\n# })","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data=os.listdir('./train_new/cats/')\n# categories=[]\nfor i in data:\n    validationDogsSearchObj = re.search(\"5\\d\\d\\d\", i)\n    if validationDogsSearchObj:\n        shutil.move('./train_new/cats/'+i, 'valid_new/cats/')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.listdir('./train_new/cats/')[1555]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"im = img.imread('./train_new/cats/cat.12167.jpg') \n  \n# show image \nplt.imshow(im) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_size=224\ndata_transforms = {\n    'train': transforms.Compose([\n        transforms.RandomRotation([-30, 30]),\n        transforms.Resize((input_size,input_size)),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n    'valid': transforms.Compose([\n        transforms.Resize(input_size),\n        transforms.CenterCrop(input_size),\n        transforms.ToTensor(),\n        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n    ]),\n}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = torchvision.datasets.ImageFolder(root=\"./train_new/\", transform=data_transforms['train'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"valid_data = torchvision.datasets.ImageFolder(root=\"./valid_new/\", transform=data_transforms['valid'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(len(train_data),len(valid_data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dl=DataLoader(train_data, batch_size=64, shuffle=True)\nvalid_dl=DataLoader(valid_data, batch_size=64, shuffle=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# train_dl[0]\n# data_loaders={'train':train_dl,'valid':valid_dl}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Network(nn.Module):\n    def __init__(self):\n        super(Network, self).__init__()\n        self.conv1=nn.Conv2d(in_channels=3,out_channels=16,kernel_size=5,stride=1,padding=0)\n        self.relu1=nn.ReLU()\n        self.maxpool1=nn.MaxPool2d(kernel_size=2)\n        self.conv2=nn.Conv2d(in_channels=16,out_channels=32,kernel_size=5,stride=1,padding=0)\n        self.relu2=nn.ReLU()\n        self.maxpool2=nn.MaxPool2d(kernel_size=2)\n        self.conv3=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,stride=1,padding=0)\n        self.relu3=nn.ReLU()\n        self.maxpool3=nn.MaxPool2d(kernel_size=2)\n        self.fc=nn.Linear(64*24*24,2)\n    def forward(self,x):\n        out=self.conv1(x)\n        out=self.relu1(out)\n        out=self.maxpool1(out)\n        \n        out = self.conv2(out)\n        out = self.relu2(out)\n        out=self.maxpool2(out)\n        \n        out = self.conv3(out)\n        out = self.relu3(out)\n        out = self.maxpool3(out)\n        \n        out = out.view(out.size(0), -1)\n        out = self.fc(out)\n        \n        return out","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net = Network()\nnet.to(device)\noptimizer = optim.SGD(net.parameters(),0.001, momentum=0.7)\ncriterion  = nn.CrossEntropyLoss()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for a,b in enumerate(train_dl,0):\n    inputs, labels = data\n    print(inputs[0].shape)\n    break","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net(inputs)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(25):  # loop over the dataset multiple times\n\n    running_loss = 0.0\n    for i, data in enumerate(train_dl, 0):\n        # get the inputs; data is a list of [inputs, labels]\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n        # zero the parameter gradients\n        optimizer.zero_grad()\n\n        # forward + backward + optimize\n        outputs = net(inputs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        # print statistics\n        running_loss += loss.item()\n        if i % 50 == 0:    # print every 2000 mini-batches\n            print('[%d, %5d] loss: %.3f' %\n                  (epoch + 1, i + 1, running_loss / 2000))\n            running_loss = 0.0\n\nprint('Finished Training')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"net.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"c=torch.zeros([1, 32, 53, 53], dtype=torch.float32)\nc.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"maxpool1 = nn.MaxPool2d(kernel_size=2)\ncnn1 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5, stride=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"o=cnn1(c)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m=maxpool1(o)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"o.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"m.shape","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}